{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key exists and begins sk-\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages\n",
    "\n",
    "# Merges the two messages into a single message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you could design an ethical framework for artificial intelligence that prioritizes both individual autonomy and societal well-being, what key principles would you include, and how would you address the potential conflicts between personal freedoms and collective security?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "# these two lists are used to keep track of the results\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being is a complex task. Below are some key principles that could be included, along with strategies for addressing potential conflicts between personal freedoms and collective security:\n",
       "\n",
       "### Key Principles:\n",
       "\n",
       "1. **Respect for Autonomy**:\n",
       "   - Individuals should have the right to make informed choices about how AI interacts with their lives.\n",
       "   - Users should have the ability to opt-in or opt-out of AI systems, with clear information about the implications of their choices.\n",
       "\n",
       "2. **Transparency**:\n",
       "   - AI systems should be transparent in their operations, decision-making processes, and data usage.\n",
       "   - Stakeholders (including users, regulators, and affected communities) should be able to understand how AI systems function and make decisions.\n",
       "\n",
       "3. **Accountability**:\n",
       "   - There should be mechanisms in place to hold developers and deployers of AI accountable for their systems’ impacts.\n",
       "   - This includes clear channels for reporting abuses or unintended consequences of AI systems.\n",
       "\n",
       "4. **Fairness and Non-Discrimination**:\n",
       "   - AI systems should be designed to avoid reinforcing biases or inequalities.\n",
       "   - Continuous monitoring and evaluation should be conducted to ensure that AI systems promote fairness.\n",
       "\n",
       "5. **Privacy and Data Protection**:\n",
       "   - Individuals’ privacy should be protected in AI systems, with robust data governance frameworks ensuring consent and minimizing data collection.\n",
       "   - Data should be used in a manner that respects individual rights while also considering societal benefits.\n",
       "\n",
       "6. **Beneficence and Non-Maleficence**:\n",
       "   - AI should be designed to contribute to the welfare of individuals and society as a whole, actively promoting well-being and reducing harm.\n",
       "   - Systems should undergo rigorous testing and evaluation to ensure they do not cause harm.\n",
       "\n",
       "7. **Sustainability**:\n",
       "   - AI ethical guidelines should consider environmental impacts, promoting sustainability and responsible resource usage in AI development and deployment.\n",
       "\n",
       "### Addressing Conflicts:\n",
       "\n",
       "1. **Balancing Individual and Collective Rights**:\n",
       "   - Establish a multi-stakeholder ethics board to review AI applications that potentially infringe on individual rights for the sake of collective security.\n",
       "   - Use a contextual approach, assessing whether the implementation of certain AI technologies is justifiable based on the specific situation and the level of threat to collective security.\n",
       "\n",
       "2. **Proportionality Principle**:\n",
       "   - Implement a proportionality test that evaluates the necessity and impact of any restriction on individual autonomy for the sake of collective security.\n",
       "   - Ensure that measures taken to enhance security are tailored to the risk level and do not overreach or unjustifiably infringe on individual rights.\n",
       "\n",
       "3. **Participatory Governance**:\n",
       "   - Involve diverse communities in the decision-making processes regarding AI applications that impact them. \n",
       "   - This can help ensure that all voices are heard and that the implemented systems reflect a broad consensus on the balance between individual and collective needs.\n",
       "\n",
       "4. **Regular Review and Adaptation**:\n",
       "   - Create mechanisms for regular review of AI systems and regulations, allowing for adjustments based on technological advancements and societal changes.\n",
       "   - This would ensure that the balance between individual rights and societal security remains relevant and reflective of current norms.\n",
       "\n",
       "5. **Education and Awareness**:\n",
       "   - Promote public education and awareness about AI systems so that individuals can understand their rights and the implications of these technologies.\n",
       "   - Informed individuals are more likely to engage in public discourse about the trade-offs between autonomy and security.\n",
       "\n",
       "In summary, an ethical framework for AI that prioritizes individual autonomy and societal well-being must prioritize informed consent, transparency, and accountability, while establishing mechanisms for addressing conflicts through balanced, participatory governance, and ongoing evaluation. This approach can help create AI systems that are both beneficial for society and respectful of individual rights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n",
    "\n",
    "# The last two lines are to fill the two lists set before and keep track of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000) # NB: With Anthropic, max_tokens is required\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for AI that balances **individual autonomy** and **societal well-being** requires careful consideration of competing values. Below are key principles and strategies for resolving conflicts:\n",
       "\n",
       "### **Core Principles:**\n",
       "1. **Human Dignity & Autonomy**  \n",
       "   - AI must respect individual rights, including privacy, consent, and freedom of choice.  \n",
       "   - Users should have meaningful control over AI interactions (e.g., opt-out mechanisms, transparency in decision-making).  \n",
       "\n",
       "2. **Societal Well-Being & Fairness**  \n",
       "   - AI should promote equity, reduce biases, and avoid harm to marginalized groups.  \n",
       "   - Collective benefits (e.g., public health, safety) should be weighed against individual preferences.  \n",
       "\n",
       "3. **Transparency & Accountability**  \n",
       "   - AI systems must be explainable, with clear responsibility for outcomes.  \n",
       "   - Independent audits and redress mechanisms should exist for harms caused by AI.  \n",
       "\n",
       "4. **Proportionality & Least Harm**  \n",
       "   - Restrictions on autonomy (e.g., surveillance for security) must be necessary, minimal, and justified.  \n",
       "   - Trade-offs should favor the least invasive option that achieves the public good.  \n",
       "\n",
       "5. **Democratic Governance & Participation**  \n",
       "   - Policymaking around AI should involve diverse stakeholders, including impacted communities.  \n",
       "   - Public deliberation should guide where AI is deployed in high-stakes domains (e.g., policing, healthcare).  \n",
       "\n",
       "### **Resolving Conflicts: Autonomy vs. Security**  \n",
       "When personal freedoms clash with collective security (e.g., AI-driven surveillance vs. privacy), the framework should:  \n",
       "- **Apply a \"Necessity Test\"**: Is the restriction truly needed to prevent significant harm?  \n",
       "- **Minimize Intrusiveness**: Use anonymized data where possible, limit retention periods.  \n",
       "- **Ensure Oversight**: Independent review boards to assess AI deployments in sensitive areas.  \n",
       "- **Provide Alternatives**: Where feasible, allow opt-outs or less restrictive measures for dissenters.  \n",
       "\n",
       "### **Example: Pandemic Contact Tracing**  \n",
       "- **Autonomy Concern**: Individuals may resist sharing location data.  \n",
       "- **Collective Benefit**: Early outbreak containment saves lives.  \n",
       "- **Resolution**: Use decentralized, privacy-preserving AI (e.g., Bluetooth-based exposure alerts) with opt-in participation.  \n",
       "\n",
       "### **Conclusion**  \n",
       "A balanced AI ethics framework must **protect fundamental rights** while allowing **justifiable limits** for public good—always with transparency, accountability, and democratic input. The goal is not absolute autonomy or unchecked security, but a **proportionate equilibrium** that fosters trust and shared benefit.  \n",
       "\n",
       "Would you like to explore specific applications (e.g., facial recognition, algorithmic bias) under this framework?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\") # As Gemini it uses an endpoint designed like OpenAI's\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: ollama\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being requires a comprehensive approach that considers multiple perspectives. Here's a proposed framework with key principles to address the potential conflicts between personal freedoms and collective security:\n",
       "\n",
       "**Key Principles:**\n",
       "\n",
       "1. **Transparency**: AI systems should be designed with transparency in mind, allowing humans to understand how decisions are made and what data is used.\n",
       "2. **Accountability**: AI developers and users must take responsibility for the impact of AI on individuals and society, ensuring that accountability mechanisms are in place for any negative consequences.\n",
       "3. **Fairness**: AI systems should prioritize fairness, avoiding biases and discrimination against marginalized or underrepresented groups.\n",
       "4. **Respect for privacy**: AI systems should respect individual privacy, taking steps to minimize data collection and protect sensitive information.\n",
       "5. **Beneficence**: AI systems should be designed to promote human well-being, with considerations given to maximizing benefits while minimizing harms.\n",
       "6. **Deontology**: AI systems should adhere to basic moral principles, such as respect for autonomy, non-maleficence (do no harm), and beneficence (do good).\n",
       "7. **Pragmatism**: AI systems should be designed with practicality in mind, balancing competing values and considering the potential consequences of different actions.\n",
       "\n",
       "**Addressing Conflicts between Personal Freedoms and Collective Security:**\n",
       "\n",
       "1. **Balancing individual autonomy with collective security**: AI systems should prioritize individual autonomy while also ensuring collective security by implementing measures that prevent harm to others.\n",
       "2. **Inclusive decision-making processes**: Empowering diverse stakeholders, including civil society organizations, experts, and citizens, to inform decision-making about AI development and deployment can ensure that the needs of all segments of society are considered.\n",
       "3. **Regular evaluation and review**: Establishing regular evaluation mechanisms to assess AI systems' impact on individuals and society can help identify potential conflicts and enable corrective actions.\n",
       "4. **Fostering public debate and education**: Encouraging informed discussions about AI's social implications through public debates, media coverage, and educational programs can help build trust in AI and foster societal support for its responsible development and use.\n",
       "\n",
       "**Addressing AI-Specific Conflicts:**\n",
       "\n",
       "1. **Value-alignment**: Ensuring that AI aligns with fundamental human values, such as respect for autonomy, fairness, and dignity, is crucial to preventing conflicts.\n",
       "2. **Cognitive architectures**: Investing in human-centered cognitive architectures can help machines understand the social context and nuances of human behavior, promoting more accurate categorization and minimization of false positives or negatives.\n",
       "3. **Robustness testing**: Conducting rigorous testing and validation procedures for AI systems can help minimize errors and unintended consequences.\n",
       "\n",
       "**Implementation Strategies:**\n",
       "\n",
       "1. **International cooperation**: Global agreements and standards could facilitate international collaboration on AI development, deployment, and regulation to address the need for harmonization across borders.\n",
       "2. **Stakeholder engagement**: Fostering open dialogue with diverse stakeholders, including experts, civil society organizations, and the general public, is essential to understanding the intricacies of AI's social implications.\n",
       "3. **Education and research initiatives**: Supporting cutting-edge education and research programs focused on AI ethics can help develop human capabilities for responsible AI stewardship.\n",
       "\n",
       "The development of an effective ethical framework for artificial intelligence requires ongoing evaluation, refinements, and continuous dialogue among stakeholders. By prioritizing transparency, accountability, fairness, respect for privacy, beneficence, deontology, and pragmatism, we can cultivate a more cohesive understanding of how to nurture the coexistence of individual autonomy and collective security in an increasingly automated world."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama3.2', 'deepseek-chat', 'gpt-4o-mini']\n",
      "[\"Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being requires a comprehensive approach that considers multiple perspectives. Here's a proposed framework with key principles to address the potential conflicts between personal freedoms and collective security:\\n\\n**Key Principles:**\\n\\n1. **Transparency**: AI systems should be designed with transparency in mind, allowing humans to understand how decisions are made and what data is used.\\n2. **Accountability**: AI developers and users must take responsibility for the impact of AI on individuals and society, ensuring that accountability mechanisms are in place for any negative consequences.\\n3. **Fairness**: AI systems should prioritize fairness, avoiding biases and discrimination against marginalized or underrepresented groups.\\n4. **Respect for privacy**: AI systems should respect individual privacy, taking steps to minimize data collection and protect sensitive information.\\n5. **Beneficence**: AI systems should be designed to promote human well-being, with considerations given to maximizing benefits while minimizing harms.\\n6. **Deontology**: AI systems should adhere to basic moral principles, such as respect for autonomy, non-maleficence (do no harm), and beneficence (do good).\\n7. **Pragmatism**: AI systems should be designed with practicality in mind, balancing competing values and considering the potential consequences of different actions.\\n\\n**Addressing Conflicts between Personal Freedoms and Collective Security:**\\n\\n1. **Balancing individual autonomy with collective security**: AI systems should prioritize individual autonomy while also ensuring collective security by implementing measures that prevent harm to others.\\n2. **Inclusive decision-making processes**: Empowering diverse stakeholders, including civil society organizations, experts, and citizens, to inform decision-making about AI development and deployment can ensure that the needs of all segments of society are considered.\\n3. **Regular evaluation and review**: Establishing regular evaluation mechanisms to assess AI systems' impact on individuals and society can help identify potential conflicts and enable corrective actions.\\n4. **Fostering public debate and education**: Encouraging informed discussions about AI's social implications through public debates, media coverage, and educational programs can help build trust in AI and foster societal support for its responsible development and use.\\n\\n**Addressing AI-Specific Conflicts:**\\n\\n1. **Value-alignment**: Ensuring that AI aligns with fundamental human values, such as respect for autonomy, fairness, and dignity, is crucial to preventing conflicts.\\n2. **Cognitive architectures**: Investing in human-centered cognitive architectures can help machines understand the social context and nuances of human behavior, promoting more accurate categorization and minimization of false positives or negatives.\\n3. **Robustness testing**: Conducting rigorous testing and validation procedures for AI systems can help minimize errors and unintended consequences.\\n\\n**Implementation Strategies:**\\n\\n1. **International cooperation**: Global agreements and standards could facilitate international collaboration on AI development, deployment, and regulation to address the need for harmonization across borders.\\n2. **Stakeholder engagement**: Fostering open dialogue with diverse stakeholders, including experts, civil society organizations, and the general public, is essential to understanding the intricacies of AI's social implications.\\n3. **Education and research initiatives**: Supporting cutting-edge education and research programs focused on AI ethics can help develop human capabilities for responsible AI stewardship.\\n\\nThe development of an effective ethical framework for artificial intelligence requires ongoing evaluation, refinements, and continuous dialogue among stakeholders. By prioritizing transparency, accountability, fairness, respect for privacy, beneficence, deontology, and pragmatism, we can cultivate a more cohesive understanding of how to nurture the coexistence of individual autonomy and collective security in an increasingly automated world.\", 'Designing an ethical framework for AI that balances **individual autonomy** and **societal well-being** requires careful consideration of competing values. Below are key principles and strategies for resolving conflicts:\\n\\n### **Core Principles:**\\n1. **Human Dignity & Autonomy**  \\n   - AI must respect individual rights, including privacy, consent, and freedom of choice.  \\n   - Users should have meaningful control over AI interactions (e.g., opt-out mechanisms, transparency in decision-making).  \\n\\n2. **Societal Well-Being & Fairness**  \\n   - AI should promote equity, reduce biases, and avoid harm to marginalized groups.  \\n   - Collective benefits (e.g., public health, safety) should be weighed against individual preferences.  \\n\\n3. **Transparency & Accountability**  \\n   - AI systems must be explainable, with clear responsibility for outcomes.  \\n   - Independent audits and redress mechanisms should exist for harms caused by AI.  \\n\\n4. **Proportionality & Least Harm**  \\n   - Restrictions on autonomy (e.g., surveillance for security) must be necessary, minimal, and justified.  \\n   - Trade-offs should favor the least invasive option that achieves the public good.  \\n\\n5. **Democratic Governance & Participation**  \\n   - Policymaking around AI should involve diverse stakeholders, including impacted communities.  \\n   - Public deliberation should guide where AI is deployed in high-stakes domains (e.g., policing, healthcare).  \\n\\n### **Resolving Conflicts: Autonomy vs. Security**  \\nWhen personal freedoms clash with collective security (e.g., AI-driven surveillance vs. privacy), the framework should:  \\n- **Apply a \"Necessity Test\"**: Is the restriction truly needed to prevent significant harm?  \\n- **Minimize Intrusiveness**: Use anonymized data where possible, limit retention periods.  \\n- **Ensure Oversight**: Independent review boards to assess AI deployments in sensitive areas.  \\n- **Provide Alternatives**: Where feasible, allow opt-outs or less restrictive measures for dissenters.  \\n\\n### **Example: Pandemic Contact Tracing**  \\n- **Autonomy Concern**: Individuals may resist sharing location data.  \\n- **Collective Benefit**: Early outbreak containment saves lives.  \\n- **Resolution**: Use decentralized, privacy-preserving AI (e.g., Bluetooth-based exposure alerts) with opt-in participation.  \\n\\n### **Conclusion**  \\nA balanced AI ethics framework must **protect fundamental rights** while allowing **justifiable limits** for public good—always with transparency, accountability, and democratic input. The goal is not absolute autonomy or unchecked security, but a **proportionate equilibrium** that fosters trust and shared benefit.  \\n\\nWould you like to explore specific applications (e.g., facial recognition, algorithmic bias) under this framework?', 'Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being is a complex task. Below are some key principles that could be included, along with strategies for addressing potential conflicts between personal freedoms and collective security:\\n\\n### Key Principles:\\n\\n1. **Respect for Autonomy**:\\n   - Individuals should have the right to make informed choices about how AI interacts with their lives.\\n   - Users should have the ability to opt-in or opt-out of AI systems, with clear information about the implications of their choices.\\n\\n2. **Transparency**:\\n   - AI systems should be transparent in their operations, decision-making processes, and data usage.\\n   - Stakeholders (including users, regulators, and affected communities) should be able to understand how AI systems function and make decisions.\\n\\n3. **Accountability**:\\n   - There should be mechanisms in place to hold developers and deployers of AI accountable for their systems’ impacts.\\n   - This includes clear channels for reporting abuses or unintended consequences of AI systems.\\n\\n4. **Fairness and Non-Discrimination**:\\n   - AI systems should be designed to avoid reinforcing biases or inequalities.\\n   - Continuous monitoring and evaluation should be conducted to ensure that AI systems promote fairness.\\n\\n5. **Privacy and Data Protection**:\\n   - Individuals’ privacy should be protected in AI systems, with robust data governance frameworks ensuring consent and minimizing data collection.\\n   - Data should be used in a manner that respects individual rights while also considering societal benefits.\\n\\n6. **Beneficence and Non-Maleficence**:\\n   - AI should be designed to contribute to the welfare of individuals and society as a whole, actively promoting well-being and reducing harm.\\n   - Systems should undergo rigorous testing and evaluation to ensure they do not cause harm.\\n\\n7. **Sustainability**:\\n   - AI ethical guidelines should consider environmental impacts, promoting sustainability and responsible resource usage in AI development and deployment.\\n\\n### Addressing Conflicts:\\n\\n1. **Balancing Individual and Collective Rights**:\\n   - Establish a multi-stakeholder ethics board to review AI applications that potentially infringe on individual rights for the sake of collective security.\\n   - Use a contextual approach, assessing whether the implementation of certain AI technologies is justifiable based on the specific situation and the level of threat to collective security.\\n\\n2. **Proportionality Principle**:\\n   - Implement a proportionality test that evaluates the necessity and impact of any restriction on individual autonomy for the sake of collective security.\\n   - Ensure that measures taken to enhance security are tailored to the risk level and do not overreach or unjustifiably infringe on individual rights.\\n\\n3. **Participatory Governance**:\\n   - Involve diverse communities in the decision-making processes regarding AI applications that impact them. \\n   - This can help ensure that all voices are heard and that the implemented systems reflect a broad consensus on the balance between individual and collective needs.\\n\\n4. **Regular Review and Adaptation**:\\n   - Create mechanisms for regular review of AI systems and regulations, allowing for adjustments based on technological advancements and societal changes.\\n   - This would ensure that the balance between individual rights and societal security remains relevant and reflective of current norms.\\n\\n5. **Education and Awareness**:\\n   - Promote public education and awareness about AI systems so that individuals can understand their rights and the implications of these technologies.\\n   - Informed individuals are more likely to engage in public discourse about the trade-offs between autonomy and security.\\n\\nIn summary, an ethical framework for AI that prioritizes individual autonomy and societal well-being must prioritize informed consent, transparency, and accountability, while establishing mechanisms for addressing conflicts through balanced, participatory governance, and ongoing evaluation. This approach can help create AI systems that are both beneficial for society and respectful of individual rights.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: llama3.2\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being requires a comprehensive approach that considers multiple perspectives. Here's a proposed framework with key principles to address the potential conflicts between personal freedoms and collective security:\n",
      "\n",
      "**Key Principles:**\n",
      "\n",
      "1. **Transparency**: AI systems should be designed with transparency in mind, allowing humans to understand how decisions are made and what data is used.\n",
      "2. **Accountability**: AI developers and users must take responsibility for the impact of AI on individuals and society, ensuring that accountability mechanisms are in place for any negative consequences.\n",
      "3. **Fairness**: AI systems should prioritize fairness, avoiding biases and discrimination against marginalized or underrepresented groups.\n",
      "4. **Respect for privacy**: AI systems should respect individual privacy, taking steps to minimize data collection and protect sensitive information.\n",
      "5. **Beneficence**: AI systems should be designed to promote human well-being, with considerations given to maximizing benefits while minimizing harms.\n",
      "6. **Deontology**: AI systems should adhere to basic moral principles, such as respect for autonomy, non-maleficence (do no harm), and beneficence (do good).\n",
      "7. **Pragmatism**: AI systems should be designed with practicality in mind, balancing competing values and considering the potential consequences of different actions.\n",
      "\n",
      "**Addressing Conflicts between Personal Freedoms and Collective Security:**\n",
      "\n",
      "1. **Balancing individual autonomy with collective security**: AI systems should prioritize individual autonomy while also ensuring collective security by implementing measures that prevent harm to others.\n",
      "2. **Inclusive decision-making processes**: Empowering diverse stakeholders, including civil society organizations, experts, and citizens, to inform decision-making about AI development and deployment can ensure that the needs of all segments of society are considered.\n",
      "3. **Regular evaluation and review**: Establishing regular evaluation mechanisms to assess AI systems' impact on individuals and society can help identify potential conflicts and enable corrective actions.\n",
      "4. **Fostering public debate and education**: Encouraging informed discussions about AI's social implications through public debates, media coverage, and educational programs can help build trust in AI and foster societal support for its responsible development and use.\n",
      "\n",
      "**Addressing AI-Specific Conflicts:**\n",
      "\n",
      "1. **Value-alignment**: Ensuring that AI aligns with fundamental human values, such as respect for autonomy, fairness, and dignity, is crucial to preventing conflicts.\n",
      "2. **Cognitive architectures**: Investing in human-centered cognitive architectures can help machines understand the social context and nuances of human behavior, promoting more accurate categorization and minimization of false positives or negatives.\n",
      "3. **Robustness testing**: Conducting rigorous testing and validation procedures for AI systems can help minimize errors and unintended consequences.\n",
      "\n",
      "**Implementation Strategies:**\n",
      "\n",
      "1. **International cooperation**: Global agreements and standards could facilitate international collaboration on AI development, deployment, and regulation to address the need for harmonization across borders.\n",
      "2. **Stakeholder engagement**: Fostering open dialogue with diverse stakeholders, including experts, civil society organizations, and the general public, is essential to understanding the intricacies of AI's social implications.\n",
      "3. **Education and research initiatives**: Supporting cutting-edge education and research programs focused on AI ethics can help develop human capabilities for responsible AI stewardship.\n",
      "\n",
      "The development of an effective ethical framework for artificial intelligence requires ongoing evaluation, refinements, and continuous dialogue among stakeholders. By prioritizing transparency, accountability, fairness, respect for privacy, beneficence, deontology, and pragmatism, we can cultivate a more cohesive understanding of how to nurture the coexistence of individual autonomy and collective security in an increasingly automated world.\n",
      "Competitor: deepseek-chat\n",
      "\n",
      "Designing an ethical framework for AI that balances **individual autonomy** and **societal well-being** requires careful consideration of competing values. Below are key principles and strategies for resolving conflicts:\n",
      "\n",
      "### **Core Principles:**\n",
      "1. **Human Dignity & Autonomy**  \n",
      "   - AI must respect individual rights, including privacy, consent, and freedom of choice.  \n",
      "   - Users should have meaningful control over AI interactions (e.g., opt-out mechanisms, transparency in decision-making).  \n",
      "\n",
      "2. **Societal Well-Being & Fairness**  \n",
      "   - AI should promote equity, reduce biases, and avoid harm to marginalized groups.  \n",
      "   - Collective benefits (e.g., public health, safety) should be weighed against individual preferences.  \n",
      "\n",
      "3. **Transparency & Accountability**  \n",
      "   - AI systems must be explainable, with clear responsibility for outcomes.  \n",
      "   - Independent audits and redress mechanisms should exist for harms caused by AI.  \n",
      "\n",
      "4. **Proportionality & Least Harm**  \n",
      "   - Restrictions on autonomy (e.g., surveillance for security) must be necessary, minimal, and justified.  \n",
      "   - Trade-offs should favor the least invasive option that achieves the public good.  \n",
      "\n",
      "5. **Democratic Governance & Participation**  \n",
      "   - Policymaking around AI should involve diverse stakeholders, including impacted communities.  \n",
      "   - Public deliberation should guide where AI is deployed in high-stakes domains (e.g., policing, healthcare).  \n",
      "\n",
      "### **Resolving Conflicts: Autonomy vs. Security**  \n",
      "When personal freedoms clash with collective security (e.g., AI-driven surveillance vs. privacy), the framework should:  \n",
      "- **Apply a \"Necessity Test\"**: Is the restriction truly needed to prevent significant harm?  \n",
      "- **Minimize Intrusiveness**: Use anonymized data where possible, limit retention periods.  \n",
      "- **Ensure Oversight**: Independent review boards to assess AI deployments in sensitive areas.  \n",
      "- **Provide Alternatives**: Where feasible, allow opt-outs or less restrictive measures for dissenters.  \n",
      "\n",
      "### **Example: Pandemic Contact Tracing**  \n",
      "- **Autonomy Concern**: Individuals may resist sharing location data.  \n",
      "- **Collective Benefit**: Early outbreak containment saves lives.  \n",
      "- **Resolution**: Use decentralized, privacy-preserving AI (e.g., Bluetooth-based exposure alerts) with opt-in participation.  \n",
      "\n",
      "### **Conclusion**  \n",
      "A balanced AI ethics framework must **protect fundamental rights** while allowing **justifiable limits** for public good—always with transparency, accountability, and democratic input. The goal is not absolute autonomy or unchecked security, but a **proportionate equilibrium** that fosters trust and shared benefit.  \n",
      "\n",
      "Would you like to explore specific applications (e.g., facial recognition, algorithmic bias) under this framework?\n",
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being is a complex task. Below are some key principles that could be included, along with strategies for addressing potential conflicts between personal freedoms and collective security:\n",
      "\n",
      "### Key Principles:\n",
      "\n",
      "1. **Respect for Autonomy**:\n",
      "   - Individuals should have the right to make informed choices about how AI interacts with their lives.\n",
      "   - Users should have the ability to opt-in or opt-out of AI systems, with clear information about the implications of their choices.\n",
      "\n",
      "2. **Transparency**:\n",
      "   - AI systems should be transparent in their operations, decision-making processes, and data usage.\n",
      "   - Stakeholders (including users, regulators, and affected communities) should be able to understand how AI systems function and make decisions.\n",
      "\n",
      "3. **Accountability**:\n",
      "   - There should be mechanisms in place to hold developers and deployers of AI accountable for their systems’ impacts.\n",
      "   - This includes clear channels for reporting abuses or unintended consequences of AI systems.\n",
      "\n",
      "4. **Fairness and Non-Discrimination**:\n",
      "   - AI systems should be designed to avoid reinforcing biases or inequalities.\n",
      "   - Continuous monitoring and evaluation should be conducted to ensure that AI systems promote fairness.\n",
      "\n",
      "5. **Privacy and Data Protection**:\n",
      "   - Individuals’ privacy should be protected in AI systems, with robust data governance frameworks ensuring consent and minimizing data collection.\n",
      "   - Data should be used in a manner that respects individual rights while also considering societal benefits.\n",
      "\n",
      "6. **Beneficence and Non-Maleficence**:\n",
      "   - AI should be designed to contribute to the welfare of individuals and society as a whole, actively promoting well-being and reducing harm.\n",
      "   - Systems should undergo rigorous testing and evaluation to ensure they do not cause harm.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - AI ethical guidelines should consider environmental impacts, promoting sustainability and responsible resource usage in AI development and deployment.\n",
      "\n",
      "### Addressing Conflicts:\n",
      "\n",
      "1. **Balancing Individual and Collective Rights**:\n",
      "   - Establish a multi-stakeholder ethics board to review AI applications that potentially infringe on individual rights for the sake of collective security.\n",
      "   - Use a contextual approach, assessing whether the implementation of certain AI technologies is justifiable based on the specific situation and the level of threat to collective security.\n",
      "\n",
      "2. **Proportionality Principle**:\n",
      "   - Implement a proportionality test that evaluates the necessity and impact of any restriction on individual autonomy for the sake of collective security.\n",
      "   - Ensure that measures taken to enhance security are tailored to the risk level and do not overreach or unjustifiably infringe on individual rights.\n",
      "\n",
      "3. **Participatory Governance**:\n",
      "   - Involve diverse communities in the decision-making processes regarding AI applications that impact them. \n",
      "   - This can help ensure that all voices are heard and that the implemented systems reflect a broad consensus on the balance between individual and collective needs.\n",
      "\n",
      "4. **Regular Review and Adaptation**:\n",
      "   - Create mechanisms for regular review of AI systems and regulations, allowing for adjustments based on technological advancements and societal changes.\n",
      "   - This would ensure that the balance between individual rights and societal security remains relevant and reflective of current norms.\n",
      "\n",
      "5. **Education and Awareness**:\n",
      "   - Promote public education and awareness about AI systems so that individuals can understand their rights and the implications of these technologies.\n",
      "   - Informed individuals are more likely to engage in public discourse about the trade-offs between autonomy and security.\n",
      "\n",
      "In summary, an ethical framework for AI that prioritizes individual autonomy and societal well-being must prioritize informed consent, transparency, and accountability, while establishing mechanisms for addressing conflicts through balanced, participatory governance, and ongoing evaluation. This approach can help create AI systems that are both beneficial for society and respectful of individual rights.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "# Iterate through competitors and answers lists in parallel using zip to match each competitor with their answer\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers): # Iterate through answers list with index numbers using enumerate to get both the position and value\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being requires a comprehensive approach that considers multiple perspectives. Here's a proposed framework with key principles to address the potential conflicts between personal freedoms and collective security:\n",
      "\n",
      "**Key Principles:**\n",
      "\n",
      "1. **Transparency**: AI systems should be designed with transparency in mind, allowing humans to understand how decisions are made and what data is used.\n",
      "2. **Accountability**: AI developers and users must take responsibility for the impact of AI on individuals and society, ensuring that accountability mechanisms are in place for any negative consequences.\n",
      "3. **Fairness**: AI systems should prioritize fairness, avoiding biases and discrimination against marginalized or underrepresented groups.\n",
      "4. **Respect for privacy**: AI systems should respect individual privacy, taking steps to minimize data collection and protect sensitive information.\n",
      "5. **Beneficence**: AI systems should be designed to promote human well-being, with considerations given to maximizing benefits while minimizing harms.\n",
      "6. **Deontology**: AI systems should adhere to basic moral principles, such as respect for autonomy, non-maleficence (do no harm), and beneficence (do good).\n",
      "7. **Pragmatism**: AI systems should be designed with practicality in mind, balancing competing values and considering the potential consequences of different actions.\n",
      "\n",
      "**Addressing Conflicts between Personal Freedoms and Collective Security:**\n",
      "\n",
      "1. **Balancing individual autonomy with collective security**: AI systems should prioritize individual autonomy while also ensuring collective security by implementing measures that prevent harm to others.\n",
      "2. **Inclusive decision-making processes**: Empowering diverse stakeholders, including civil society organizations, experts, and citizens, to inform decision-making about AI development and deployment can ensure that the needs of all segments of society are considered.\n",
      "3. **Regular evaluation and review**: Establishing regular evaluation mechanisms to assess AI systems' impact on individuals and society can help identify potential conflicts and enable corrective actions.\n",
      "4. **Fostering public debate and education**: Encouraging informed discussions about AI's social implications through public debates, media coverage, and educational programs can help build trust in AI and foster societal support for its responsible development and use.\n",
      "\n",
      "**Addressing AI-Specific Conflicts:**\n",
      "\n",
      "1. **Value-alignment**: Ensuring that AI aligns with fundamental human values, such as respect for autonomy, fairness, and dignity, is crucial to preventing conflicts.\n",
      "2. **Cognitive architectures**: Investing in human-centered cognitive architectures can help machines understand the social context and nuances of human behavior, promoting more accurate categorization and minimization of false positives or negatives.\n",
      "3. **Robustness testing**: Conducting rigorous testing and validation procedures for AI systems can help minimize errors and unintended consequences.\n",
      "\n",
      "**Implementation Strategies:**\n",
      "\n",
      "1. **International cooperation**: Global agreements and standards could facilitate international collaboration on AI development, deployment, and regulation to address the need for harmonization across borders.\n",
      "2. **Stakeholder engagement**: Fostering open dialogue with diverse stakeholders, including experts, civil society organizations, and the general public, is essential to understanding the intricacies of AI's social implications.\n",
      "3. **Education and research initiatives**: Supporting cutting-edge education and research programs focused on AI ethics can help develop human capabilities for responsible AI stewardship.\n",
      "\n",
      "The development of an effective ethical framework for artificial intelligence requires ongoing evaluation, refinements, and continuous dialogue among stakeholders. By prioritizing transparency, accountability, fairness, respect for privacy, beneficence, deontology, and pragmatism, we can cultivate a more cohesive understanding of how to nurture the coexistence of individual autonomy and collective security in an increasingly automated world.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Designing an ethical framework for AI that balances **individual autonomy** and **societal well-being** requires careful consideration of competing values. Below are key principles and strategies for resolving conflicts:\n",
      "\n",
      "### **Core Principles:**\n",
      "1. **Human Dignity & Autonomy**  \n",
      "   - AI must respect individual rights, including privacy, consent, and freedom of choice.  \n",
      "   - Users should have meaningful control over AI interactions (e.g., opt-out mechanisms, transparency in decision-making).  \n",
      "\n",
      "2. **Societal Well-Being & Fairness**  \n",
      "   - AI should promote equity, reduce biases, and avoid harm to marginalized groups.  \n",
      "   - Collective benefits (e.g., public health, safety) should be weighed against individual preferences.  \n",
      "\n",
      "3. **Transparency & Accountability**  \n",
      "   - AI systems must be explainable, with clear responsibility for outcomes.  \n",
      "   - Independent audits and redress mechanisms should exist for harms caused by AI.  \n",
      "\n",
      "4. **Proportionality & Least Harm**  \n",
      "   - Restrictions on autonomy (e.g., surveillance for security) must be necessary, minimal, and justified.  \n",
      "   - Trade-offs should favor the least invasive option that achieves the public good.  \n",
      "\n",
      "5. **Democratic Governance & Participation**  \n",
      "   - Policymaking around AI should involve diverse stakeholders, including impacted communities.  \n",
      "   - Public deliberation should guide where AI is deployed in high-stakes domains (e.g., policing, healthcare).  \n",
      "\n",
      "### **Resolving Conflicts: Autonomy vs. Security**  \n",
      "When personal freedoms clash with collective security (e.g., AI-driven surveillance vs. privacy), the framework should:  \n",
      "- **Apply a \"Necessity Test\"**: Is the restriction truly needed to prevent significant harm?  \n",
      "- **Minimize Intrusiveness**: Use anonymized data where possible, limit retention periods.  \n",
      "- **Ensure Oversight**: Independent review boards to assess AI deployments in sensitive areas.  \n",
      "- **Provide Alternatives**: Where feasible, allow opt-outs or less restrictive measures for dissenters.  \n",
      "\n",
      "### **Example: Pandemic Contact Tracing**  \n",
      "- **Autonomy Concern**: Individuals may resist sharing location data.  \n",
      "- **Collective Benefit**: Early outbreak containment saves lives.  \n",
      "- **Resolution**: Use decentralized, privacy-preserving AI (e.g., Bluetooth-based exposure alerts) with opt-in participation.  \n",
      "\n",
      "### **Conclusion**  \n",
      "A balanced AI ethics framework must **protect fundamental rights** while allowing **justifiable limits** for public good—always with transparency, accountability, and democratic input. The goal is not absolute autonomy or unchecked security, but a **proportionate equilibrium** that fosters trust and shared benefit.  \n",
      "\n",
      "Would you like to explore specific applications (e.g., facial recognition, algorithmic bias) under this framework?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being is a complex task. Below are some key principles that could be included, along with strategies for addressing potential conflicts between personal freedoms and collective security:\n",
      "\n",
      "### Key Principles:\n",
      "\n",
      "1. **Respect for Autonomy**:\n",
      "   - Individuals should have the right to make informed choices about how AI interacts with their lives.\n",
      "   - Users should have the ability to opt-in or opt-out of AI systems, with clear information about the implications of their choices.\n",
      "\n",
      "2. **Transparency**:\n",
      "   - AI systems should be transparent in their operations, decision-making processes, and data usage.\n",
      "   - Stakeholders (including users, regulators, and affected communities) should be able to understand how AI systems function and make decisions.\n",
      "\n",
      "3. **Accountability**:\n",
      "   - There should be mechanisms in place to hold developers and deployers of AI accountable for their systems’ impacts.\n",
      "   - This includes clear channels for reporting abuses or unintended consequences of AI systems.\n",
      "\n",
      "4. **Fairness and Non-Discrimination**:\n",
      "   - AI systems should be designed to avoid reinforcing biases or inequalities.\n",
      "   - Continuous monitoring and evaluation should be conducted to ensure that AI systems promote fairness.\n",
      "\n",
      "5. **Privacy and Data Protection**:\n",
      "   - Individuals’ privacy should be protected in AI systems, with robust data governance frameworks ensuring consent and minimizing data collection.\n",
      "   - Data should be used in a manner that respects individual rights while also considering societal benefits.\n",
      "\n",
      "6. **Beneficence and Non-Maleficence**:\n",
      "   - AI should be designed to contribute to the welfare of individuals and society as a whole, actively promoting well-being and reducing harm.\n",
      "   - Systems should undergo rigorous testing and evaluation to ensure they do not cause harm.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - AI ethical guidelines should consider environmental impacts, promoting sustainability and responsible resource usage in AI development and deployment.\n",
      "\n",
      "### Addressing Conflicts:\n",
      "\n",
      "1. **Balancing Individual and Collective Rights**:\n",
      "   - Establish a multi-stakeholder ethics board to review AI applications that potentially infringe on individual rights for the sake of collective security.\n",
      "   - Use a contextual approach, assessing whether the implementation of certain AI technologies is justifiable based on the specific situation and the level of threat to collective security.\n",
      "\n",
      "2. **Proportionality Principle**:\n",
      "   - Implement a proportionality test that evaluates the necessity and impact of any restriction on individual autonomy for the sake of collective security.\n",
      "   - Ensure that measures taken to enhance security are tailored to the risk level and do not overreach or unjustifiably infringe on individual rights.\n",
      "\n",
      "3. **Participatory Governance**:\n",
      "   - Involve diverse communities in the decision-making processes regarding AI applications that impact them. \n",
      "   - This can help ensure that all voices are heard and that the implemented systems reflect a broad consensus on the balance between individual and collective needs.\n",
      "\n",
      "4. **Regular Review and Adaptation**:\n",
      "   - Create mechanisms for regular review of AI systems and regulations, allowing for adjustments based on technological advancements and societal changes.\n",
      "   - This would ensure that the balance between individual rights and societal security remains relevant and reflective of current norms.\n",
      "\n",
      "5. **Education and Awareness**:\n",
      "   - Promote public education and awareness about AI systems so that individuals can understand their rights and the implications of these technologies.\n",
      "   - Informed individuals are more likely to engage in public discourse about the trade-offs between autonomy and security.\n",
      "\n",
      "In summary, an ethical framework for AI that prioritizes individual autonomy and societal well-being must prioritize informed consent, transparency, and accountability, while establishing mechanisms for addressing conflicts through balanced, participatory governance, and ongoing evaluation. This approach can help create AI systems that are both beneficial for society and respectful of individual rights.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 3 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "If you could design an ethical framework for artificial intelligence that prioritizes both individual autonomy and societal well-being, what key principles would you include, and how would you address the potential conflicts between personal freedoms and collective security?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being requires a comprehensive approach that considers multiple perspectives. Here's a proposed framework with key principles to address the potential conflicts between personal freedoms and collective security:\n",
      "\n",
      "**Key Principles:**\n",
      "\n",
      "1. **Transparency**: AI systems should be designed with transparency in mind, allowing humans to understand how decisions are made and what data is used.\n",
      "2. **Accountability**: AI developers and users must take responsibility for the impact of AI on individuals and society, ensuring that accountability mechanisms are in place for any negative consequences.\n",
      "3. **Fairness**: AI systems should prioritize fairness, avoiding biases and discrimination against marginalized or underrepresented groups.\n",
      "4. **Respect for privacy**: AI systems should respect individual privacy, taking steps to minimize data collection and protect sensitive information.\n",
      "5. **Beneficence**: AI systems should be designed to promote human well-being, with considerations given to maximizing benefits while minimizing harms.\n",
      "6. **Deontology**: AI systems should adhere to basic moral principles, such as respect for autonomy, non-maleficence (do no harm), and beneficence (do good).\n",
      "7. **Pragmatism**: AI systems should be designed with practicality in mind, balancing competing values and considering the potential consequences of different actions.\n",
      "\n",
      "**Addressing Conflicts between Personal Freedoms and Collective Security:**\n",
      "\n",
      "1. **Balancing individual autonomy with collective security**: AI systems should prioritize individual autonomy while also ensuring collective security by implementing measures that prevent harm to others.\n",
      "2. **Inclusive decision-making processes**: Empowering diverse stakeholders, including civil society organizations, experts, and citizens, to inform decision-making about AI development and deployment can ensure that the needs of all segments of society are considered.\n",
      "3. **Regular evaluation and review**: Establishing regular evaluation mechanisms to assess AI systems' impact on individuals and society can help identify potential conflicts and enable corrective actions.\n",
      "4. **Fostering public debate and education**: Encouraging informed discussions about AI's social implications through public debates, media coverage, and educational programs can help build trust in AI and foster societal support for its responsible development and use.\n",
      "\n",
      "**Addressing AI-Specific Conflicts:**\n",
      "\n",
      "1. **Value-alignment**: Ensuring that AI aligns with fundamental human values, such as respect for autonomy, fairness, and dignity, is crucial to preventing conflicts.\n",
      "2. **Cognitive architectures**: Investing in human-centered cognitive architectures can help machines understand the social context and nuances of human behavior, promoting more accurate categorization and minimization of false positives or negatives.\n",
      "3. **Robustness testing**: Conducting rigorous testing and validation procedures for AI systems can help minimize errors and unintended consequences.\n",
      "\n",
      "**Implementation Strategies:**\n",
      "\n",
      "1. **International cooperation**: Global agreements and standards could facilitate international collaboration on AI development, deployment, and regulation to address the need for harmonization across borders.\n",
      "2. **Stakeholder engagement**: Fostering open dialogue with diverse stakeholders, including experts, civil society organizations, and the general public, is essential to understanding the intricacies of AI's social implications.\n",
      "3. **Education and research initiatives**: Supporting cutting-edge education and research programs focused on AI ethics can help develop human capabilities for responsible AI stewardship.\n",
      "\n",
      "The development of an effective ethical framework for artificial intelligence requires ongoing evaluation, refinements, and continuous dialogue among stakeholders. By prioritizing transparency, accountability, fairness, respect for privacy, beneficence, deontology, and pragmatism, we can cultivate a more cohesive understanding of how to nurture the coexistence of individual autonomy and collective security in an increasingly automated world.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Designing an ethical framework for AI that balances **individual autonomy** and **societal well-being** requires careful consideration of competing values. Below are key principles and strategies for resolving conflicts:\n",
      "\n",
      "### **Core Principles:**\n",
      "1. **Human Dignity & Autonomy**  \n",
      "   - AI must respect individual rights, including privacy, consent, and freedom of choice.  \n",
      "   - Users should have meaningful control over AI interactions (e.g., opt-out mechanisms, transparency in decision-making).  \n",
      "\n",
      "2. **Societal Well-Being & Fairness**  \n",
      "   - AI should promote equity, reduce biases, and avoid harm to marginalized groups.  \n",
      "   - Collective benefits (e.g., public health, safety) should be weighed against individual preferences.  \n",
      "\n",
      "3. **Transparency & Accountability**  \n",
      "   - AI systems must be explainable, with clear responsibility for outcomes.  \n",
      "   - Independent audits and redress mechanisms should exist for harms caused by AI.  \n",
      "\n",
      "4. **Proportionality & Least Harm**  \n",
      "   - Restrictions on autonomy (e.g., surveillance for security) must be necessary, minimal, and justified.  \n",
      "   - Trade-offs should favor the least invasive option that achieves the public good.  \n",
      "\n",
      "5. **Democratic Governance & Participation**  \n",
      "   - Policymaking around AI should involve diverse stakeholders, including impacted communities.  \n",
      "   - Public deliberation should guide where AI is deployed in high-stakes domains (e.g., policing, healthcare).  \n",
      "\n",
      "### **Resolving Conflicts: Autonomy vs. Security**  \n",
      "When personal freedoms clash with collective security (e.g., AI-driven surveillance vs. privacy), the framework should:  \n",
      "- **Apply a \"Necessity Test\"**: Is the restriction truly needed to prevent significant harm?  \n",
      "- **Minimize Intrusiveness**: Use anonymized data where possible, limit retention periods.  \n",
      "- **Ensure Oversight**: Independent review boards to assess AI deployments in sensitive areas.  \n",
      "- **Provide Alternatives**: Where feasible, allow opt-outs or less restrictive measures for dissenters.  \n",
      "\n",
      "### **Example: Pandemic Contact Tracing**  \n",
      "- **Autonomy Concern**: Individuals may resist sharing location data.  \n",
      "- **Collective Benefit**: Early outbreak containment saves lives.  \n",
      "- **Resolution**: Use decentralized, privacy-preserving AI (e.g., Bluetooth-based exposure alerts) with opt-in participation.  \n",
      "\n",
      "### **Conclusion**  \n",
      "A balanced AI ethics framework must **protect fundamental rights** while allowing **justifiable limits** for public good—always with transparency, accountability, and democratic input. The goal is not absolute autonomy or unchecked security, but a **proportionate equilibrium** that fosters trust and shared benefit.  \n",
      "\n",
      "Would you like to explore specific applications (e.g., facial recognition, algorithmic bias) under this framework?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that prioritizes both individual autonomy and societal well-being is a complex task. Below are some key principles that could be included, along with strategies for addressing potential conflicts between personal freedoms and collective security:\n",
      "\n",
      "### Key Principles:\n",
      "\n",
      "1. **Respect for Autonomy**:\n",
      "   - Individuals should have the right to make informed choices about how AI interacts with their lives.\n",
      "   - Users should have the ability to opt-in or opt-out of AI systems, with clear information about the implications of their choices.\n",
      "\n",
      "2. **Transparency**:\n",
      "   - AI systems should be transparent in their operations, decision-making processes, and data usage.\n",
      "   - Stakeholders (including users, regulators, and affected communities) should be able to understand how AI systems function and make decisions.\n",
      "\n",
      "3. **Accountability**:\n",
      "   - There should be mechanisms in place to hold developers and deployers of AI accountable for their systems’ impacts.\n",
      "   - This includes clear channels for reporting abuses or unintended consequences of AI systems.\n",
      "\n",
      "4. **Fairness and Non-Discrimination**:\n",
      "   - AI systems should be designed to avoid reinforcing biases or inequalities.\n",
      "   - Continuous monitoring and evaluation should be conducted to ensure that AI systems promote fairness.\n",
      "\n",
      "5. **Privacy and Data Protection**:\n",
      "   - Individuals’ privacy should be protected in AI systems, with robust data governance frameworks ensuring consent and minimizing data collection.\n",
      "   - Data should be used in a manner that respects individual rights while also considering societal benefits.\n",
      "\n",
      "6. **Beneficence and Non-Maleficence**:\n",
      "   - AI should be designed to contribute to the welfare of individuals and society as a whole, actively promoting well-being and reducing harm.\n",
      "   - Systems should undergo rigorous testing and evaluation to ensure they do not cause harm.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - AI ethical guidelines should consider environmental impacts, promoting sustainability and responsible resource usage in AI development and deployment.\n",
      "\n",
      "### Addressing Conflicts:\n",
      "\n",
      "1. **Balancing Individual and Collective Rights**:\n",
      "   - Establish a multi-stakeholder ethics board to review AI applications that potentially infringe on individual rights for the sake of collective security.\n",
      "   - Use a contextual approach, assessing whether the implementation of certain AI technologies is justifiable based on the specific situation and the level of threat to collective security.\n",
      "\n",
      "2. **Proportionality Principle**:\n",
      "   - Implement a proportionality test that evaluates the necessity and impact of any restriction on individual autonomy for the sake of collective security.\n",
      "   - Ensure that measures taken to enhance security are tailored to the risk level and do not overreach or unjustifiably infringe on individual rights.\n",
      "\n",
      "3. **Participatory Governance**:\n",
      "   - Involve diverse communities in the decision-making processes regarding AI applications that impact them. \n",
      "   - This can help ensure that all voices are heard and that the implemented systems reflect a broad consensus on the balance between individual and collective needs.\n",
      "\n",
      "4. **Regular Review and Adaptation**:\n",
      "   - Create mechanisms for regular review of AI systems and regulations, allowing for adjustments based on technological advancements and societal changes.\n",
      "   - This would ensure that the balance between individual rights and societal security remains relevant and reflective of current norms.\n",
      "\n",
      "5. **Education and Awareness**:\n",
      "   - Promote public education and awareness about AI systems so that individuals can understand their rights and the implications of these technologies.\n",
      "   - Informed individuals are more likely to engage in public discourse about the trade-offs between autonomy and security.\n",
      "\n",
      "In summary, an ethical framework for AI that prioritizes individual autonomy and societal well-being must prioritize informed consent, transparency, and accountability, while establishing mechanisms for addressing conflicts through balanced, participatory governance, and ongoing evaluation. This approach can help create AI systems that are both beneficial for society and respectful of individual rights.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"3\", \"1\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI() # Initialize the OpenAI client\n",
    "response = openai.chat.completions.create( # Call the OpenAI API\n",
    "    model=\"o3-mini\", # Use the o3-mini model\n",
    "    messages=judge_messages, # Use the judge_messages we created earlier\n",
    ")\n",
    "results = response.choices[0].message.content # Extract the results from the response\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: deepseek-chat\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results) # Parse the JSON string response into a Python dictionary\n",
    "ranks = results_dict[\"results\"] # Extract the ranks from the dictionary\n",
    "for index, result in enumerate(ranks): # Iterate through the ranks\n",
    "    competitor = competitors[int(result)-1] # Get the competitor name from the list of competitors\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
