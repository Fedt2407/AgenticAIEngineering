{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Week 5 Day 1\n",
    "\n",
    "AutoGen AgentChat!\n",
    "\n",
    "This should look simple and familiar, because it has a lot in common with Crew and OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First concept: the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: This way we call the LLM from OpenAI\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: This way we create a model from Ollama\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "ollamamodel_client = OllamaChatCompletionClient(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second concept: The Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 11, 17, 10, 5, 2, 796428, tzinfo=datetime.timezone.utc), content=\"I'd like to go to London\", type='TextMessage')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This way we create the user message, note this is a text message\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "message = TextMessage(content=\"I'd like to go to London\", source=\"user\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third concept: The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way we create the Agent by importing the AssistantAgent class\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"airline_agent\",\n",
    "    model_client=model_client, # Here we pass the LLM model created before\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers.\",\n",
    "    model_client_stream=True # Here we say that the result of the agent must be returned in the stream\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together with on_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great choice! London is like a big, bustling, historical theme park—only with more rain and fewer roller coasters!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we put all together to receive a response from the Agent\n",
    "# CancellationToken lets you abort or interrupt long-running agent operations in AutoGen, \n",
    "# allowing graceful cancellation of processing (for example, if the user wants to stop a query).\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "# here we create the response that is of course an asyncronous process\n",
    "# to do this we use the method .on_messasge on the agent\n",
    "# we pass the message created before and the cancellation_token to interrupt the chat\n",
    "response = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "response.chat_message.content # here we receive the content of the reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a local database of ticket prices\n",
    "Here we create a sqlite DB to retrieve ticket prices.\n",
    "It's a small example of RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Delete existing database file if it exists\n",
    "if os.path.exists(\"tickets.db\"):\n",
    "    os.remove(\"tickets.db\")\n",
    "\n",
    "# Create the database and the table\n",
    "conn = sqlite3.connect(\"tickets.db\")  # Connect to (or create) the database file 'tickets.db'\n",
    "c = conn.cursor()  # Create a cursor object to execute SQL commands. Now we can execute SQL commands on the database just created.\n",
    "# Create the 'cities' table with city_name as the primary key and round_trip_price as a real number\n",
    "c.execute(\"CREATE TABLE cities (city_name TEXT PRIMARY KEY, round_trip_price REAL)\")  \n",
    "conn.commit()  # Save (commit) the changes made to the database\n",
    "conn.close()  # Close the connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate our database\n",
    "# We create a simple function to save records in the DB by passing city name and ticket price as parameters\n",
    "def save_city_price(city_name, round_trip_price):\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    # Insert or update the ticket price for a city in the database; replaces the record if the city already exists\n",
    "    c.execute(\"REPLACE INTO cities (city_name, round_trip_price) VALUES (?, ?)\", (city_name.lower(), round_trip_price))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Some cities!\n",
    "save_city_price(\"London\", 299)\n",
    "save_city_price(\"Paris\", 399)\n",
    "save_city_price(\"Rome\", 499)\n",
    "save_city_price(\"Madrid\", 550)\n",
    "save_city_price(\"Barcelona\", 580)\n",
    "save_city_price(\"Berlin\", 525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get price for a city\n",
    "# The method connects with the database, select the city based on its name and return it.\n",
    "def get_city_price(city_name: str) -> float | None:\n",
    "    \"\"\" Get the roundtrip ticket price to travel to the city \"\"\"\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT round_trip_price FROM cities WHERE city_name = ?\", (city_name.lower(),))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    return result[0] if result else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_city_price(\"Rome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to recreate the agent and equip it with tools\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "smart_agent = AssistantAgent(\n",
    "    name=\"smart_airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers, including the price of a roundtrip ticket.\",\n",
    "    model_client_stream=True, # We want the resukt is returned back in the stream\n",
    "    tools=[get_city_price], # This is the tool just created to retrieve the ticket price in the DB\n",
    "    reflect_on_tool_use=True # Enables the agent to reflect on its previous tool use and adjust its responses accordingly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_daIL366mfv0ijaEdKsljQAT4', arguments='{\"city_name\":\"London\"}', name='get_city_price')]\n",
      "[FunctionExecutionResult(content='299.0', name='get_city_price', call_id='call_daIL366mfv0ijaEdKsljQAT4', is_error=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A London trip? That's as cheap as a cuppa tea at £299! Just don't forget your umbrella! ☔️✈️\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create the response with the asyncronous process\n",
    "response = await smart_agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "# These two lines allow to print the inner messages to understant what is going on\n",
    "for inner_message in response.inner_messages:\n",
    "    print(inner_message.content)\n",
    "response.chat_message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
